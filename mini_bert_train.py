import torch
import numpy as np
import pandas as pd
import os
import re
import jieba
import random
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
from collections import defaultdict
from transformers import (
    BertTokenizerFast,
    BertForSequenceClassification,
    Trainer,
    TrainingArguments,
    DataCollatorWithPadding,
    EarlyStoppingCallback
)
from torch.utils.data import Dataset

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.family"] = ["SimHei", "DejaVu Sans"]
plt.rcParams['axes.unicode_minus'] = False


# 1. å…¨å±€å·¥å…·å‡½æ•°ï¼šå¼ºåˆ¶æ¸…æ´—æ‰€æœ‰éå­—ç¬¦ä¸²æ•°æ®
def force_clean_text(input_data):
    if pd.isna(input_data) or input_data is None:
        return "æ— æœ‰æ•ˆå†…å®¹"
    elif isinstance(input_data, bool):
        return "å¸ƒå°”å€¼æ•°æ®"
    elif isinstance(input_data, (int, float)):
        return f"æ•°å­—æ•°æ®{input_data}"
    elif isinstance(input_data, (list, dict, tuple, set)):
        return str(input_data)[:100]
    elif isinstance(input_data, str):
        clean_str = re.sub(r"\s+", " ", input_data.strip())
        return clean_str if clean_str else "æ— æœ‰æ•ˆå†…å®¹"
    else:
        return str(input_data)[:100]


# 2. è®¾å¤‡åˆå§‹åŒ–
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"å½“å‰ä½¿ç”¨è®¡ç®—è®¾å¤‡ï¼š{device}")
if device.type == "cuda":
    print(f"æ˜¾å­˜æ€»é‡ï¼š{torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")
    print(f"åˆå§‹å‰©ä½™æ˜¾å­˜ï¼š{torch.cuda.mem_get_info()[0] / 1024 ** 3:.2f} GB")


# 3. æ•°æ®é›†ç±»ï¼ˆç¡®ä¿æ ‡ç­¾æ˜¯åˆ—è¡¨ï¼‰
class ScamDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=128, is_train=False):
        self.texts = [force_clean_text(text) for text in texts]
        self.labels = [int(label) for label in list(labels)]  # å¼ºåˆ¶è½¬åˆ—è¡¨+int
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.is_train = is_train

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        if self.is_train and text != "æ— æœ‰æ•ˆå†…å®¹":
            text = self.augment_text(text)

        encoding = self.tokenizer(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_offsets_mapping=False,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(self.labels[idx], dtype=torch.long)
        }

    def augment_text(self, text):
        """å¢å¼ºç­–ç•¥ï¼šç©ºæ ¼+åŒä¹‰è¯+éšæœºæ’å…¥ç‰¹å¾è¯"""
        if random.random() < 0.3:
            text = re.sub(r"([ï¼Œã€‚, .ï¼›;ï¼š:])", r"\1 ", text)
        synonyms = {
            "åˆ·å•": ["åˆ·é”€é‡", "åˆ·å¥½è¯„"],
            "å«ä»˜": ["é¢„ä»˜", "ä»£ä»˜"],
            "è¿”ç°": ["è¿”åˆ©", "è¿”é’±"],
            "æŠ•èµ„": ["ç†è´¢", "æŠ•é’±"],
            "å®¢æœ": ["å”®å", "å®¢æœäººå‘˜"],
            "éªŒè¯ç ": ["æ ¡éªŒç ", "éªŒè¯ä¿¡æ¯"]
        }
        for k, v_list in synonyms.items():
            if k in text and random.random() < 0.25:
                text = text.replace(k, random.choice(v_list))
        if "åˆ·å•" in text or "å«ä»˜" in text:
            insert_words = ["ä½£é‡‘", "ä»»åŠ¡å•", "æç°"]
        elif "æŠ•èµ„" in text or "ç†è´¢" in text:
            insert_words = ["é«˜æ”¶ç›Š", "å¼€æˆ·", "æ“ç›˜"]
        elif "å®¢æœ" in text or "éªŒè¯ç " in text:
            insert_words = ["é€€æ¬¾", "è´¦æˆ·", "å†»ç»“"]
        else:
            insert_words = []
        if insert_words and random.random() < 0.2:
            insert_pos = random.randint(0, len(text))
            text = text[:insert_pos] + random.choice(insert_words) + text[insert_pos:]
        return text


# 4. æ•°æ®åŠ è½½ï¼ˆå¢å¼ºç‰ˆï¼šåˆå¹¶å¤šä¸ªæ•°æ®æºï¼‰
def load_data(scam_csv_path, normal_csv_path, data_csv_path=None, normal_sample_num=500):
    all_texts = []
    all_labels = []

    # åŠ è½½è¯ˆéª—æ•°æ®
    if not os.path.exists(scam_csv_path):
        raise FileNotFoundError(f"è¯ˆéª—æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {scam_csv_path}")
    scam_df = pd.read_csv(scam_csv_path)
    required_cols = ['content', 'label']
    for col in required_cols:
        if col not in scam_df.columns:
            raise ValueError(f"è¯ˆéª—æ•°æ®ç¼ºå°‘åˆ—'{col}'ï¼Œå¯ç”¨åˆ—: {scam_df.columns.tolist()}")

    scam_df['content'] = scam_df['content'].apply(force_clean_text)
    scam_df['label'] = pd.to_numeric(scam_df['label'], errors='coerce')
    scam_df = scam_df[scam_df['content'] != "æ— æœ‰æ•ˆå†…å®¹"]
    scam_df = scam_df.dropna(subset=['label'])
    scam_df = scam_df[scam_df['label'].isin([1, 2, 3])]

    # æ ¸å¿ƒä¼˜åŒ–ï¼šç»™æ¯ç±»è¯ˆéª—æ ·æœ¬æ·»åŠ ä¸“å±ç‰¹å¾è¯ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¹ ç±»åˆ«å·®å¼‚
    def add_exclusive_feature(text, label):
        feature_map = {
            1: " [åˆ·å•è¿”åˆ©ç‰¹å¾ï¼šä»»åŠ¡è¿”åˆ©]",
            2: " [è™šå‡æŠ•èµ„ç‰¹å¾ï¼šè´·æ¬¾ç†è´¢]",
            3: " [å†’å……å®¢æœç‰¹å¾ï¼šé€€æ¬¾å¿«é€’]"
        }
        return text + feature_map.get(label, "")

    scam_df['content'] = scam_df.apply(
        lambda row: add_exclusive_feature(row['content'], row['label']), axis=1
    )

    scam_texts = scam_df['content'].tolist()
    scam_labels = scam_df['label'].tolist()
    all_texts.extend(scam_texts)
    all_labels.extend(scam_labels)
    print(f"åŠ è½½è¯ˆéª—æ•°æ®ï¼šå…±{len(scam_texts)}æ¡ï¼ˆå·²æ·»åŠ ä¸“å±ç‰¹å¾è¯ï¼‰")

    # åŠ è½½æ­£å¸¸æ•°æ®
    if not os.path.exists(normal_csv_path):
        raise FileNotFoundError(f"æ­£å¸¸æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {normal_csv_path}")
    normal_df = pd.read_csv(normal_csv_path)
    if 'content' not in normal_df.columns:
        raise ValueError(f"æ­£å¸¸æ•°æ®ç¼ºå°‘'content'åˆ—ï¼Œå¯ç”¨åˆ—: {normal_df.columns.tolist()}")

    normal_df['content'] = normal_df['content'].apply(force_clean_text)
    normal_df = normal_df[normal_df['content'] != "æ— æœ‰æ•ˆå†…å®¹"]

    sample_num = min(normal_sample_num, len(normal_df))
    normal_df_sampled = normal_df.sample(n=sample_num, random_state=42)
    normal_texts = normal_df_sampled['content'].tolist()
    normal_labels = [0] * len(normal_texts)
    all_texts.extend(normal_texts)
    all_labels.extend(normal_labels)
    print(f"åŠ è½½æ­£å¸¸æ•°æ®ï¼šå…±{len(normal_texts)}æ¡ï¼ˆæ¸…æ´—åï¼ŒæŠ½æ ·è‡ª{len(normal_df)}æ¡ï¼‰")

    # åŠ è½½é¢å¤–çš„data.csvæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if data_csv_path and os.path.exists(data_csv_path):
        print(f"\nåŠ è½½é¢å¤–æ•°æ®: {data_csv_path}")
        data_df = pd.read_csv(data_csv_path)
        if 'content' in data_df.columns and 'label' in data_df.columns:
            data_df['content'] = data_df['content'].apply(force_clean_text)
            data_df['label'] = pd.to_numeric(data_df['label'], errors='coerce')
            data_df = data_df[data_df['content'] != "æ— æœ‰æ•ˆå†…å®¹"]
            data_df = data_df.dropna(subset=['label'])
            data_df = data_df[data_df['label'].isin([0, 1, 2, 3])]

            # ç»™è¯ˆéª—æ•°æ®æ·»åŠ ç‰¹å¾è¯
            def process_data_row(row):
                text = row['content']
                label = row['label']
                if label in [1, 2, 3]:
                    text = add_exclusive_feature(text, label)
                return text

            data_df['content'] = data_df.apply(process_data_row, axis=1)

            data_texts = data_df['content'].tolist()
            data_labels = data_df['label'].tolist()
            all_texts.extend(data_texts)
            all_labels.extend(data_labels)
            print(f"åŠ è½½é¢å¤–æ•°æ®ï¼šå…±{len(data_texts)}æ¡")
        else:
            print("è­¦å‘Š: data.csvç¼ºå°‘contentæˆ–labelåˆ—")

    total_label_map = {0: "æ­£å¸¸å¯¹è¯", 1: "åˆ·å•è¿”åˆ©", 2: "è™šå‡æŠ•èµ„", 3: "å†’å……å®¢æœ"}

    # æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
    print(f"\næ€»æ ·æœ¬{len(all_texts)}æ¡ï¼Œç±»åˆ«åˆ†å¸ƒï¼š")
    label_counts = {}
    for label in [0, 1, 2, 3]:
        count = all_labels.count(label)
        label_counts[total_label_map[label]] = count
        print(f"  - {total_label_map[label]}ï¼š{count}æ¡")

    # ç»˜åˆ¶æ•°æ®åˆ†å¸ƒé¥¼å›¾
    plt.figure(figsize=(10, 6))
    plt.pie(label_counts.values(), labels=label_counts.keys(), autopct='%1.1f%%', startangle=90)
    plt.title('æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ')
    plt.savefig('data_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()

    # ç»˜åˆ¶ç±»åˆ«æ•°é‡æŸ±çŠ¶å›¾
    plt.figure(figsize=(10, 6))
    bars = plt.bar(label_counts.keys(), label_counts.values(), color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])
    plt.title('å„ç±»åˆ«æ ·æœ¬æ•°é‡')
    plt.xlabel('ç±»åˆ«')
    plt.ylabel('æ ·æœ¬æ•°é‡')
    for bar, count in zip(bars, label_counts.values()):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5,
                 f'{count}', ha='center', va='bottom')
    plt.tight_layout()
    plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()

    train_texts, temp_texts, train_labels, temp_labels = train_test_split(
        all_texts, all_labels, test_size=0.3, random_state=42, stratify=all_labels
    )
    val_texts, test_texts, val_labels, test_labels = train_test_split(
        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels
    )
    print(f"æ•°æ®åˆ†å‰²ï¼šè®­ç»ƒé›†{len(train_texts)}æ¡ï¼ŒéªŒè¯é›†{len(val_texts)}æ¡ï¼Œæµ‹è¯•é›†{len(test_texts)}æ¡")

    return (train_texts, val_texts, test_texts,
            train_labels, val_labels, test_labels)


# 5. å¸¦åŠ¨æ€æƒé‡çš„è®­ç»ƒå™¨ï¼ˆæ”¹è¿›ç‰ˆï¼‰
class DynamicWeightTrainer(Trainer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # æ ¹æ®ç±»åˆ«ä¸å¹³è¡¡è°ƒæ•´åˆå§‹æƒé‡
        self.class_weights = torch.tensor([
            1.0,  # 0-æ­£å¸¸å¯¹è¯
            2.5,  # 1-åˆ·å•è¿”åˆ©
            3.0,  # 2-è™šå‡æŠ•èµ„
            2.0  # 3-å†’å……å®¢æœ
        ], device=device, dtype=torch.float32)

        # è®­ç»ƒå†å²è®°å½•
        self.train_history = {
            'steps': [],
            'train_loss': [],
            'eval_accuracy': [],
            'eval_f1': []
        }

    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        loss = torch.nn.functional.cross_entropy(logits, labels, weight=self.class_weights.float())
        return (loss, outputs) if return_outputs else loss

    def training_step(self, model, inputs):
        """è®°å½•è®­ç»ƒæŸå¤±"""
        loss = super().training_step(model, inputs)
        if self.state.global_step % 50 == 0:
            self.train_history['steps'].append(self.state.global_step)
            self.train_history['train_loss'].append(loss.item())
        return loss

    def evaluate(self, *args, **kwargs):
        eval_result = super().evaluate(*args, **kwargs)

        # è®°å½•è¯„ä¼°æŒ‡æ ‡
        if self.state.global_step % 50 == 0:
            self.train_history['eval_accuracy'].append(eval_result.get('eval_accuracy', 0))
            self.train_history['eval_f1'].append(eval_result.get('eval_f1', 0))

        # åŠ¨æ€è°ƒæ•´æƒé‡é€»è¾‘ä¿æŒä¸å˜
        pred_output = self.predict(self.eval_dataset)
        preds = pred_output.predictions.argmax(-1)

        if isinstance(pred_output.label_ids, bool):
            labels = np.array([pred_output.label_ids])
        elif not isinstance(pred_output.label_ids, np.ndarray):
            labels = np.array(pred_output.label_ids)
        else:
            labels = pred_output.label_ids

        error_rates = []
        for label in [0, 1, 2, 3]:
            label_mask = (labels == label)
            total = sum(label_mask)
            if total == 0:
                error_rates.append(0.0)
                continue
            error_count = sum(preds[label_mask] != label)
            error_rates.append(error_count / total)

        self.class_weights = torch.tensor([
            1.0 + error_rates[0],
            2.5 + error_rates[1],
            3.0 + error_rates[2],
            2.0 + error_rates[3]
        ], device=device, dtype=torch.float32)
        print(f"\nåŠ¨æ€è°ƒæ•´ç±»åˆ«æƒé‡ï¼š{self.class_weights.tolist()}")
        return eval_result

    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        if not self.train_history['steps']:
            return

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

        # è®­ç»ƒæŸå¤±
        ax1.plot(self.train_history['steps'], self.train_history['train_loss'])
        ax1.set_title('è®­ç»ƒæŸå¤±å˜åŒ–')
        ax1.set_xlabel('è®­ç»ƒæ­¥æ•°')
        ax1.set_ylabel('æŸå¤±')
        ax1.grid(True)

        # è¯„ä¼°æŒ‡æ ‡
        if self.train_history['eval_accuracy']:
            eval_steps = self.train_history['steps'][:len(self.train_history['eval_accuracy'])]
            ax2.plot(eval_steps, self.train_history['eval_accuracy'], label='å‡†ç¡®ç‡', marker='o')
            ax2.plot(eval_steps, self.train_history['eval_f1'], label='F1åˆ†æ•°', marker='s')
            ax2.set_title('éªŒè¯é›†æ€§èƒ½')
            ax2.set_xlabel('è®­ç»ƒæ­¥æ•°')
            ax2.set_ylabel('åˆ†æ•°')
            ax2.legend()
            ax2.grid(True)

        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        plt.close()


# 6. æ¨¡å‹è®­ç»ƒ
def train_model(tokenizer_path, model_path, scam_csv, normal_csv, data_csv=None):
    # ä½¿ç”¨æœ¬åœ°BERTæ¨¡å‹
    local_bert_path = r"D:\Projects\Python\Fraud_Messages_Detection\bert-base-chinese"

    if os.path.exists(local_bert_path):
        print(f"ä½¿ç”¨æœ¬åœ°BERTæ¨¡å‹: {local_bert_path}")
        tokenizer = BertTokenizerFast.from_pretrained(local_bert_path)
    else:
        print("è­¦å‘Š: æœªæ‰¾åˆ°æœ¬åœ°BERTæ¨¡å‹ï¼Œå°è¯•ä»ç½‘ç»œåŠ è½½...")
        os.environ['TRANSFORMERS_OFFLINE'] = '1'
        tokenizer = BertTokenizerFast.from_pretrained("bert-base-chinese")

    tokenizer.save_pretrained(tokenizer_path)
    print(f"Tokenizerå·²ä¿å­˜åˆ°: {tokenizer_path}")

    # åŠ è½½æ•°æ®ï¼ˆåŒ…å«é¢å¤–æ•°æ®ï¼‰
    train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = load_data(
        scam_csv, normal_csv, data_csv
    )

    # åˆ›å»ºæ•°æ®é›†
    class ScamDatasetWithMeta(ScamDataset):
        def __init__(self, texts, labels, tokenizer, max_len=128, is_train=False):
            if is_train:
                processed_texts = texts
            else:
                processed_texts = [
                    text.replace(" [åˆ·å•è¿”åˆ©ç‰¹å¾ï¼šä»»åŠ¡è¿”åˆ©]", "").replace(" [è™šå‡æŠ•èµ„ç‰¹å¾ï¼šè´·æ¬¾ç†è´¢]", "").replace(
                        " [å†’å……å®¢æœç‰¹å¾ï¼šé€€æ¬¾å¿«é€’]", "") for text in texts]
            super().__init__(processed_texts, labels, tokenizer, max_len, is_train)
            self.raw_texts = processed_texts
            self.raw_labels = labels

    train_dataset = ScamDatasetWithMeta(train_texts, train_labels, tokenizer, is_train=True)
    val_dataset = ScamDatasetWithMeta(val_texts, val_labels, tokenizer)
    test_dataset = ScamDatasetWithMeta(test_texts, test_labels, tokenizer)

    # åŠ è½½æ¨¡å‹
    if os.path.exists(local_bert_path):
        print(f"ä»æœ¬åœ°åŠ è½½BERTæ¨¡å‹: {local_bert_path}")
        model = BertForSequenceClassification.from_pretrained(
            local_bert_path,
            num_labels=4,
            ignore_mismatched_sizes=True
        )
    else:
        print("ä»é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–...")
        model = BertForSequenceClassification.from_pretrained(
            "bert-base-chinese",
            num_labels=4
        )

    model.to(device)
    print("æ¨¡å‹åŠ è½½æˆåŠŸ")

    # è¯„ä¼°æŒ‡æ ‡
    def compute_metrics(pred):
        preds = pred.predictions.argmax(-1)
        if isinstance(pred.label_ids, bool):
            labels = np.array([pred.label_ids])
        else:
            labels = pred.label_ids
        report = classification_report(
            labels, preds, target_names=["æ­£å¸¸å¯¹è¯", "åˆ·å•è¿”åˆ©", "è™šå‡æŠ•èµ„", "å†’å……å®¢æœ"],
            output_dict=True, zero_division=0
        )
        return {
            'accuracy': report['accuracy'],
            'f1': report['macro avg']['f1-score'],
            'precision': report['macro avg']['precision'],
            'recall': report['macro avg']['recall']
        }

    # è®­ç»ƒå‚æ•°ï¼ˆæ ¹æ®æ•°æ®é‡è°ƒæ•´ï¼‰
    total_steps = len(train_dataset) * 12 // 8  # ä¼°è®¡æ€»æ­¥æ•°
    training_args = TrainingArguments(
        output_dir='./training_results',
        num_train_epochs=12,  # å¢åŠ è®­ç»ƒè½®æ¬¡
        per_device_train_batch_size=8,
        per_device_eval_batch_size=16,
        warmup_steps=min(500, total_steps // 10),
        weight_decay=0.01,
        logging_dir='./logs',
        logging_steps=50,
        evaluation_strategy='steps',
        eval_steps=min(200, total_steps // 20),
        save_strategy='steps',
        save_steps=min(200, total_steps // 20),
        load_best_model_at_end=True,
        metric_for_best_model='f1',
        learning_rate=2e-5,
        lr_scheduler_type='linear',
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        gradient_accumulation_steps=1,
        max_grad_norm=1.0,
        report_to='none'
    )

    trainer = DynamicWeightTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )

    print("\nå¼€å§‹è®­ç»ƒ...")
    trainer.train()
    trainer.plot_training_history()

    model.save_pretrained(model_path)
    tokenizer.save_pretrained(tokenizer_path)
    print(f"æ¨¡å‹ä¿å­˜è‡³ {model_path}")

    return tokenizer, model, test_dataset, trainer


# 7. è¯æ®æå–å’Œæ ‡ç­¾æ˜ å°„
type_exclusive_features = {
    "åˆ·å•è¿”åˆ©": ["è¿”åˆ©", "ä½£é‡‘", "ç‚¹èµèµšé’±", "åšä»»åŠ¡", "å«ä»˜", "åˆ·é”€é‡", "ä»»åŠ¡è¿”åˆ©"],
    "è™šå‡æŠ•èµ„": ["è´·æ¬¾", "å€Ÿæ¬¾", "åˆ©ç‡", "é¢åº¦", "æŠ•èµ„", "ç†è´¢", "é«˜æ”¶ç›Š", "è´·æ¬¾ç†è´¢"],
    "å†’å……å®¢æœ": ["å¿«é€’é—®é¢˜", "é€€æ¬¾", "è´¦æˆ·å¼‚å¸¸", "å•†å“å¬å›", "æ³¨é”€ç™½æ¡", "é€€æ¬¾å¿«é€’"],
    "æ­£å¸¸å¯¹è¯": ["å‘è´§", "ç‰©æµ", "ä»·æ ¼", "å¥½è¯„", "æ”¶è´§", "ä¼˜æƒ "]
}

label_to_scam_type = {0: "æ­£å¸¸å¯¹è¯", 1: "åˆ·å•è¿”åˆ©", 2: "è™šå‡æŠ•èµ„", 3: "å†’å……å®¢æœ"}


def extract_key_evidence(text, tokenizer, model):
    text_clean = force_clean_text(text)
    text_clean = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9]", " ", text_clean).strip()

    # æ”¹è¿›ï¼šæ›´æ™ºèƒ½çš„ç‰¹å¾è¯åŒ¹é…
    type_scores = {}
    for typ, words in type_exclusive_features.items():
        score = sum(1 for word in words if word in text_clean)
        type_scores[typ] = score

    # åªæœ‰å½“æŸä¸ªç±»åˆ«çš„ç‰¹å¾è¯æ˜æ˜¾å¤šäºå…¶ä»–ç±»åˆ«æ—¶æ‰å¼ºåˆ¶åŒ¹é…
    forced_type = None
    if type_scores:
        max_score = max(type_scores.values())
        if max_score >= 2:  # è‡³å°‘åŒ¹é…2ä¸ªç‰¹å¾è¯æ‰å¼ºåˆ¶
            for typ, score in type_scores.items():
                if score == max_score:
                    forced_type = typ
                    break

    # æ¨¡å‹æ¨ç†
    inputs = tokenizer(
        text_clean, return_tensors="pt", truncation=True, padding="max_length", max_length=128
    ).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

    pred_label = np.argmax(probs)
    pred_type = label_to_scam_type[pred_label]
    confidence = round(probs[pred_label] * 100, 2)

    if forced_type and forced_type != pred_type:
        print(f"  ç‰¹å¾è¯å¼ºåˆ¶åŒ¹é…: {pred_type} -> {forced_type}")
        pred_type = forced_type
        confidence = min(99.0, confidence + 10)  # é€‚å½“æé«˜ç½®ä¿¡åº¦

    # è¯æ®æå–
    evidence = []
    for word in type_exclusive_features[pred_type]:
        if word in text_clean and len(evidence) < 3:
            evidence.append(word)

    if len(evidence) < 3:
        cut_words = jieba.lcut(text_clean)
        related_words = [
            w for w in cut_words
            if any(feat in w for feat in type_exclusive_features[pred_type])
               and 2 <= len(w) <= 5
               and w not in ["æ— æœ‰æ•ˆå†…å®¹", "å¸ƒå°”å€¼æ•°æ®", "æ•°å­—æ•°æ®"]
        ]
        evidence += [w for w in related_words if w not in evidence][:3 - len(evidence)]

    if len(evidence) < 3:
        cut_words = jieba.lcut(text_clean)
        valid_words = [w for w in cut_words if 2 <= len(w) <= 5 and w not in ["çš„", "äº†", "åœ¨"]]
        evidence += [w for w in valid_words if w not in evidence][:3 - len(evidence)]

    return evidence, pred_type, confidence, pred_label


# 8. ç”¨CSVæµ‹è¯•é›†éªŒè¯ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å¯è§†åŒ–ï¼‰
def validate_with_csv_data(tokenizer, model, test_dataset, sample_num=50):
    # ä»æµ‹è¯•é›†ä¸­éšæœºæŠ½æ ·
    sample_indices = random.sample(range(len(test_dataset)), min(sample_num, len(test_dataset)))
    texts = [test_dataset.raw_texts[i] for i in sample_indices]
    true_labels = [test_dataset.raw_labels[i] for i in sample_indices]
    true_types = [label_to_scam_type[label] for label in true_labels]

    print("\n" + "=" * 80)
    print(f"ç”¨CSVæµ‹è¯•é›†éªŒè¯ï¼ˆéšæœºæŠ½æ ·{len(texts)}æ¡ï¼‰")
    print("=" * 80)

    all_preds = []
    all_true = []
    all_confidences = []
    all_evidences = []

    correct = 0
    for i, (text, true_label, true_type) in enumerate(zip(texts, true_labels, true_types), 1):
        evidence, pred_type, confidence, pred_label = extract_key_evidence(text, tokenizer, model)

        all_preds.append(pred_label)
        all_true.append(true_label)
        all_confidences.append(confidence)
        all_evidences.append(evidence)

        # æˆªæ–­é•¿æ–‡æœ¬æ˜¾ç¤º
        display_text = text[:120] + "..." if len(text) > 120 else text
        print(f"\nã€æµ‹è¯•æ ·æœ¬{i}ã€‘")
        print(f"æ–‡æœ¬ï¼š{display_text}")
        print(f"çœŸå®ç±»å‹ï¼š{true_type}")
        print(f"é¢„æµ‹ç±»å‹ï¼š{pred_type}ï¼ˆå¯ä¿¡åº¦ï¼š{confidence}%ï¼‰")
        print(f"å…³é”®è¯æ®ï¼š{evidence}")
        if pred_type == true_type:
            correct += 1
            print("âœ…  é¢„æµ‹æ­£ç¡®")
        else:
            print("âŒ  é¢„æµ‹é”™è¯¯")

    # è®¡ç®—å‡†ç¡®ç‡
    acc = round(correct / len(texts) * 100, 2)
    print(f"\néªŒè¯æ€»ç»“ï¼šå…±{len(texts)}æ¡ï¼Œæ­£ç¡®ç‡{acc}%")
    print("=" * 80)

    # ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š
    generate_performance_report(all_true, all_preds, all_confidences, texts, all_evidences)

    return acc


def generate_performance_report(true_labels, pred_labels, confidences, texts, evidences):
    """ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Šå’Œå¯è§†åŒ–"""

    # 1. åˆ†ç±»æŠ¥å‘Š
    print("\nã€è¯¦ç»†åˆ†ç±»æŠ¥å‘Šã€‘")
    report = classification_report(
        true_labels, pred_labels,
        target_names=[label_to_scam_type[i] for i in range(4)],
        digits=4
    )
    print(report)

    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open('classification_report.txt', 'w', encoding='utf-8') as f:
        f.write("Mini-BERT è¯ˆéª—æ£€æµ‹æ¨¡å‹åˆ†ç±»æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(report)

    # 2. æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(true_labels, pred_labels)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=[label_to_scam_type[i] for i in range(4)],
                yticklabels=[label_to_scam_type[i] for i in range(4)])
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 3. å„ç±»åˆ«å‡†ç¡®ç‡
    class_accuracies = {}
    for label in range(4):
        mask = np.array(true_labels) == label
        if sum(mask) > 0:
            accuracy = (np.array(pred_labels)[mask] == label).mean()
            class_accuracies[label_to_scam_type[label]] = accuracy * 100

    plt.figure(figsize=(10, 6))
    bars = plt.bar(class_accuracies.keys(), class_accuracies.values(),
                   color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])
    plt.title('å„ç±»åˆ«å‡†ç¡®ç‡')
    plt.ylabel('å‡†ç¡®ç‡ (%)')
    plt.ylim(0, 100)

    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, acc in zip(bars, class_accuracies.values()):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,
                 f'{acc:.1f}%', ha='center', va='bottom')

    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('class_accuracy.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 4. ç½®ä¿¡åº¦åˆ†å¸ƒ
    plt.figure(figsize=(12, 6))

    # æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
    correct_mask = np.array(pred_labels) == np.array(true_labels)
    correct_conf = np.array(confidences)[correct_mask]
    wrong_conf = np.array(confidences)[~correct_mask]

    plt.subplot(1, 2, 1)
    if len(correct_conf) > 0:
        plt.hist(correct_conf, bins=10, alpha=0.7, label='æ­£ç¡®é¢„æµ‹', color='green')
    if len(wrong_conf) > 0:
        plt.hist(wrong_conf, bins=10, alpha=0.7, label='é”™è¯¯é¢„æµ‹', color='red')
    plt.xlabel('ç½®ä¿¡åº¦ (%)')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ')
    plt.legend()

    # å„ç±»åˆ«å¹³å‡ç½®ä¿¡åº¦
    plt.subplot(1, 2, 2)
    avg_conf_by_class = []
    for label in range(4):
        mask = np.array(pred_labels) == label
        if sum(mask) > 0:
            avg_conf = np.mean(np.array(confidences)[mask])
        else:
            avg_conf = 0
        avg_conf_by_class.append(avg_conf)

    plt.bar([label_to_scam_type[i] for i in range(4)], avg_conf_by_class, color='orange')
    plt.xlabel('é¢„æµ‹ç±»åˆ«')
    plt.ylabel('å¹³å‡ç½®ä¿¡åº¦ (%)')
    plt.title('å„ç±»åˆ«å¹³å‡é¢„æµ‹ç½®ä¿¡åº¦')
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.savefig('confidence_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()

    print(f"\nâœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜:")
    print(f"   - confusion_matrix.png (æ··æ·†çŸ©é˜µ)")
    print(f"   - class_accuracy.png (å„ç±»åˆ«å‡†ç¡®ç‡)")
    print(f"   - confidence_analysis.png (ç½®ä¿¡åº¦åˆ†æ)")
    print(f"   - classification_report.txt (è¯¦ç»†åˆ†ç±»æŠ¥å‘Š)")


# ä¸»å‡½æ•°
if __name__ == "__main__":
    # ä¿®å¤è·¯å¾„é…ç½® - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    base_dir = r"D:\Projects\Python\Fraud_Messages_Detection\final_code"
    model_path = os.path.join(base_dir, "mini_bert_scam_model", "best_model")
    tokenizer_path = os.path.join(base_dir, "mini_bert_scam_model", "best_tokenizer")

    scam_csv = "preprocessed_scam_data.csv"  # è¯ˆéª—æ•°æ®CSV
    normal_csv = "label0-new1030æ­£å¸¸.csv"  # æ­£å¸¸æ•°æ®CSV
    data_csv = "data.csv"  # æ–°å¢æ•°æ®æº

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(model_path, exist_ok=True)
    os.makedirs(tokenizer_path, exist_ok=True)

    print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {model_path}")
    print(f"Tokenizerä¿å­˜è·¯å¾„: {tokenizer_path}")

    # è®­ç»ƒæ¨¡å‹
    try:
        tokenizer, model, test_dataset, trainer = train_model(
            tokenizer_path, model_path, scam_csv, normal_csv, data_csv
        )
    except Exception as e:
        print(f"è®­ç»ƒå¤±è´¥ï¼š{e}")
        import traceback

        traceback.print_exc()
        exit(1)

    # éªŒè¯ï¼ˆç”¨CSVæµ‹è¯•é›†éšæœºæŠ½æ ·ï¼‰
    accuracy = validate_with_csv_data(tokenizer, model, test_dataset, sample_num=50)

    print(f"\nğŸ‰ è®­ç»ƒå’ŒéªŒè¯å®Œæˆï¼æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {accuracy}%")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
    print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåœ¨å½“å‰ç›®å½•")